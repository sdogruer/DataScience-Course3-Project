Source Data: Human Activity Recognition Using Smartphones Data Set 
(http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)
Source Data Link: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

About The Experiment:

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. 
Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) 
wearing a smartphone (Samsung Galaxy S II) on the waist. 
Using its embedded accelerometer and gyroscope, 
we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. 
The experiments have been video-recorded to label the data manually. 
The obtained dataset has been randomly partitioned into two sets, 
where 70% of the volunteers was selected for generating the training data and 30% the test data.

Information About The Data Set:

Several txt files in the zip file are read into R, and their contents are decsribed below:

activity_labels.txt: Links the class labels with their activity name.
features.txt: List of all features.
X_train.txt: Training set.
y_train.txt: Training labels.
X_test.txt: Test set.
y_test.txt: Test labels.
subject_train.txt: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. 
subject_test.txt: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.

Feautes form the variable names of training and test data. These represent the observations that come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ.
Then, a Fast Fourier Transform (FFT) was applied to some of these signals.
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.
'-t' denotes 'time' and '-f' denotes 'frequency'.

The variables that measured include:

tBodyAcc-XYZ
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMagtGravityAccMag
tBodyAccJerkMagtBodyGyroMag
tBodyGyroJerkMagfBodyAcc-XYZ
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag
fBodyGyroMag
fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 
mean(): Mean value
std(): Standard deviation
mad(): Median absolute deviation 
max(): Largest value in array
min(): Smallest value in array
sma(): Signal magnitude area
energy(): Energy measure. Sum of the squares divided by the number of values. 
iqr(): Interquartile range 
entropy(): Signal entropy
arCoeff(): Autorregresion coefficients with Burg order equal to 4
correlation(): correlation coefficient between two signals
maxInds(): index of the frequency component with largest magnitude
meanFreq(): Weighted average of the frequency components to obtain a mean frequency
skewness(): skewness of the frequency domain signal 
kurtosis(): kurtosis of the frequency domain signal 
bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.
angle(): Angle between to vectors.

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:
gravityMean
tBodyAccMean
tBodyAccJerkMean
tBodyGyroMean
tBodyGyroJerkMean

Participant and activity numbers are added to training and test data from subject_train/subject_test and y_train/y_test files.

Training and test sets are merged to form a complete data set, named as data.
Only the measurements on the mean and standard deviation for each measurement are extracted, and form a new data set as data_mn_std.
Activity numbers in data_mn_std are recoded with activity_labels, and Variable names are changed with more appropriate ones.

data_mn_std includes participants and activity names, and mean and standard deviation measurements of each variable.

Then, a new data set is created by taking averages of each variable for each activity and each participant as ave_data_mn_std.













